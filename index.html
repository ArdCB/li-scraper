<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>LinkedIn Activity → Excel</title>

  <link rel="stylesheet" href="style.css" />

  <!-- PyScript runtime -->
  <link rel="stylesheet"
        href="https://pyscript.net/releases/2024.1.1/core.css" />
  <script type="module"
          src="https://pyscript.net/releases/2024.1.1/core.js"></script>

<py-config>
  packages = ["beautifulsoup4", "openpyxl", "pandas"]
</py-config>
</head>

<body>
  <h1>LinkedIn Activity → Excel</h1>
  <p>Choose a saved LinkedIn <em>.html</em> activity page (posts or comments):</p>

  <input type="file" id="file-input" accept=".html" />
  <button id="convert-btn">Convert&nbsp;⇨</button>
  <a id="download-link" style="display:none"></a>

  <!-- controller -->
<py-script>
import js, base64, traceback, re, sys, types
from datetime import datetime
from pyodide.ffi import create_proxy
from pyodide.http import pyfetch    # for loading the .txt file at runtime

# ── lazy‑load the scraper from social_html_scraper.txt ────────────────────
_scraper = None
async def get_scraper():
    global _scraper
    if _scraper is not None:
        return _scraper            # already loaded

    resp  = await pyfetch("social_html_scraper.txt")
    code  = await resp.string()

    module = types.ModuleType("scraper")
    exec(code, module.__dict__)    # turn plain text into a live module
    sys.modules["scraper"] = module
    _scraper = module
    return module

# ── DOM elements ──────────────────────────────────────────────────────────
file_el      = js.document.getElementById("file-input")
convert_btn  = js.document.getElementById("convert-btn")
download_el  = js.document.getElementById("download-link")

convert_btn.disabled = True

def on_select(evt=None):
    convert_btn.disabled = (file_el.files.length == 0)
file_el.onchange = create_proxy(on_select)

# ── main coroutine ────────────────────────────────────────────────────────
async def convert(evt=None):
    try:
        if file_el.files.length == 0:
            return

        mod          = await get_scraper()
        fobj         = file_el.files.item(0)
        html_text    = await fobj.text()

        # run scraper
        xlsx_bytes   = mod.linkedin_html_to_excel(html_text)
        b64          = base64.b64encode(xlsx_bytes).decode()

        # build filename
        mode         = mod.detect_mode(html_text)
        timestamp    = datetime.now().strftime("%Y%m%d_%H%M%S")
        m = re.search(r"Activity\s*_?\s*(.*?)\s*_?\s*LinkedIn", fobj.name, re.I)
        person       = m.group(1).strip().replace(" ", "_") if m else "output"
        filename     = f"social_{mode}_{timestamp}_{person}.xlsx"

        # expose download link
        download_el.href          = ("data:application/vnd.openxmlformats-"
                                     "officedocument.spreadsheetml.sheet;base64," + b64)
        download_el.download      = filename
        download_el.textContent   = f"Download “{filename}”"
        download_el.style.display = "inline"

    except Exception as exc:
        js.console.error("Conversion failed:", traceback.format_exc())
        download_el.style.display = "none"

convert_btn.onclick = create_proxy(convert)
</py-script>
</body>
</html>
